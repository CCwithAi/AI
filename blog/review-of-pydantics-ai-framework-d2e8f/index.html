<!DOCTYPE html><html lang="en"><head><meta name="description" content="Pydantic's AI framework revolutionises AI development, enhancing innovation at CCwithAi, Manchester."><meta name="twitter:description" content="Pydantic's AI framework revolutionises AI development, enhancing innovation at CCwithAi, Manchester."><meta name="robots" content="index, follow"><meta property="og:locale" content="en_UK"><meta property="og:title" content="A Review of Pydantic's AI Framework by CCwithAI."><link rel="canonical" href="https://ccwithai.github.io/AI/"><meta property="og:url" content="https://ccwithai.github.io/AI/"><meta property="og:site_name" content="CCwithAi's Blog and Ai News Site"><meta name="twitter:image:src" content="https://ccwithai.github.io/AI/assets/images/7a09f3181c.png"><meta property="og:image" content="https://ccwithai.github.io/AI/assets/images/7a09f3181c.png"><meta name="twitter:card" content="summary_large_image"><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous"><link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet"><link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;500;700&display=swap" rel="stylesheet"><link href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.css" rel="stylesheet"><link href="https://cdn.jsdelivr.net/npm/@hodgef/slate-theme@3.0.9/build/post.css" rel="stylesheet"><title>CC AI Review of Pydantic's AI Framework - Game Changer!! - AI</title></head><body><script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script><script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script><div id="root" class="is-ssr"><div class="page page-post"><header class="page-header"><div class="header-nav"><div class="container"><nav class="row navbar navbar-expand-lg navbar-dark"><a class="navbar-brand logo" href="https://ccwithai.github.io/AI/">AI</a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button><div class="collapse navbar-collapse justify-content-end" id="navbarSupportedContent"><ul class="page-menu navbar-nav"><li class="nav-item"><a class="nav-link" href="https://ccwithai.github.io/AI/">Home</a><div class="dropdown-menu"></div></li><li class="nav-item active"><a class="nav-link" href="https://ccwithai.github.io/AI/blog/">Blog</a><div class="dropdown-menu"></div></li></ul></div></nav></div></div></header><main><div class="container main-container"><div class="row"><div class="col"><div class="content"><div class="post-title-container mb-2"><div class="row justify-content-between"><div class="col-12 col-lg d-lg-flex flex-column justify-content-center"><h1 class="mb-0">CC AI Review of Pydantic&#x27;s AI Framework - Game Changer!!</h1><div class="text-muted mt-3 date post-date d-flex align-items-center" title="10 Dec, 2024"><i class="fa fa-clock-o mr-2"></i><span>Published on <!-- -->10 Dec, 2024</span></div></div></div></div><div class="featured-image" style="background-image:url(https://ccwithai.github.io/AI/assets/images/7a09f3181c.png)"></div><section class="post-content mb-3 pb-5"><div class="post-inner-content"><p>```
</p><div style="font-family:Arial,sans-serif;max-width:800px;margin:20px auto;padding:20px;line-height:1.6">
    <h1 style="color:#000;margin-bottom:20px;font-size:2.5em">PydanticAI: Bringing the FastAPI Feel to Generative AI Application Development<br><br></h1>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">The landscape of web development was irrevocably changed with the arrival of FastAPI. Built upon the robust foundation of Pydantic, FastAPI offered a breath of fresh air – an innovative, ergonomic design that prioritised developer experience without sacrificing performance. It was a framework that simply felt <em>right</em> for modern Python web applications.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Interestingly, Pydantic's influence extends far beyond web servers. Look under the hood of virtually any agent framework or Large Language Model (LLM) library in Python, and you'll likely find Pydantic diligently validating data. Yet, when the team behind Pydantic embarked on their own LLM journey with Pydantic Logfire, they recognised a gap. The intuitive, streamlined feeling of FastAPI was conspicuously absent in the existing GenAI toolkits. This realisation sparked the creation of PydanticAI, a Python Agent Framework born from a simple yet powerful aim: to transplant that beloved FastAPI feeling directly into the realm of Generative AI application development.<br><br>Personally I love Pydantic AI and use it in all my production apps.<br><br><strong style="background-color:#d9d9d9"><a href="https://github.com/CCwithAi/pydantic_ai_tutorial.git" target="_blank">Here is a link to my github repository for you to check out</a> </strong>-- a Python Agent Framework designed to make it easier to build production-grade applications with Generative AI.</p>

    <h2 style="color:#000;margin-top:30px;margin-bottom:15px;font-size:1.8em">Why Choose PydanticAI?</h2>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">PydanticAI isn't just another agent framework; it arrives with a pedigree and a philosophy that sets it apart. Here's a breakdown of the core reasons to consider PydanticAI for your next GenAI project:</p>

    <ul style="list-style-type:disc;margin-left:20px;margin-bottom:20px">
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Built by the Pydantic Team:</strong> This is a significant advantage from the outset. The creators of Pydantic are deeply embedded in the Python GenAI ecosystem. Pydantic is the validation backbone for giants like the OpenAI SDK, Anthropic SDK, LangChain, LlamaIndex, AutoGPT, Transformers, CrewAI, Instructor, and countless others. This lineage guarantees a framework built on solid foundations and a profound understanding of the challenges and nuances of working with AI models.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Model-Agnostic Design:</strong> In a rapidly evolving landscape, flexibility is paramount. PydanticAI embraces model agnosticism, offering native support for a wide array of providers including OpenAI, Anthropic, Gemini, Deepseek, Ollama, Groq, Cohere, and Mistral. Furthermore, its architecture includes a straightforward interface, empowering developers to seamlessly integrate support for additional models as they emerge. This future-proofs your applications and prevents vendor lock-in.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Seamless Pydantic Logfire Integration:</strong> Debugging and monitoring LLM applications can be notoriously opaque. PydanticAI addresses this head-on with its tight integration with Pydantic Logfire. This powerful combination provides real-time debugging capabilities, performance monitoring, and insightful behaviour tracking for your LLM-powered creations. Understanding the inner workings of your agents becomes significantly easier, accelerating development and ensuring production stability.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Type-Safe from the Ground Up:</strong> Leveraging Pydantic's core strength, PydanticAI prioritises type safety. It is designed to make type checking not just a formality, but a powerful tool for building robust and predictable AI applications. This emphasis on types improves code clarity, reduces errors, and enhances the overall developer experience, especially in complex agent orchestrations.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Python-Centric Design Philosophy:</strong> PydanticAI champions Python's inherent strengths. It encourages the use of familiar Pythonic control flow and agent composition techniques. This deliberate design choice makes it remarkably easy to apply standard Python best practices – the same methodologies you would employ in any conventional (non-AI) software project – to your AI-driven initiatives. This reduces the learning curve and promotes maintainable, idiomatic code.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Structured and Validated Responses:</strong> Harnessing the data validation prowess of Pydantic, PydanticAI ensures that model outputs are not just text blobs, but structured, validated data. By defining Pydantic models for your expected responses, you guarantee consistency across different runs and simplify downstream processing. This structured approach is crucial for building reliable and predictable AI systems.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Optional Dependency Injection System:</strong> PydanticAI incorporates an optional dependency injection system, a feature often associated with more mature frameworks. This system allows you to inject data and services into your agent's system prompts, tools, and result validators. This seemingly advanced feature is incredibly practical, particularly for testing and evaluation-driven iterative development, promoting modularity and testability.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Streamed Responses for Real-Time Interactions:</strong> In user-facing AI applications, responsiveness is key. PydanticAI's support for streamed LLM outputs delivers continuous, immediate results. Crucially, this streaming is coupled with real-time validation, ensuring rapid and accurate responses, enhancing the user experience and perceived performance of your applications.</li>
        <li style="color:#000;margin-bottom:10px;font-size:1.1em"><strong>Graph Support with Pydantic Graph:</strong> For complex AI applications where intricate agent interactions are needed, managing control flow can quickly become unwieldy. PydanticAI, in conjunction with Pydantic Graph, offers a solution. Pydantic Graph allows you to define agent interactions and workflows as graphs using Python type hints. This declarative approach provides a powerful way to manage complexity and avoid the dreaded "spaghetti code" often associated with intricate application logic.</li>
    </ul>

    <h2 style="color:#000;margin-top:30px;margin-bottom:15px;font-size:1.8em">Diving into PydanticAI in Practice</h2>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">To truly appreciate the capabilities of PydanticAI, let's explore some practical examples, mirroring an exploration conducted by Andy, a seasoned AI practitioner. These examples showcase the core concepts and demonstrate how PydanticAI brings structure and clarity to agent development.</p>

    <h3 style="color:#000;margin-top:25px;margin-bottom:10px;font-size:1.5em">The Basic Agent: Hello World</h3>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Every framework introduction deserves a "Hello World" moment. In PydanticAI, this starts with defining a model and an agent. First, selecting the LLM:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">from pydantic_ai import OpenAIModel, Agent

model = OpenAIModel(model_name="gpt-4")
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Here, we instantiate an OpenAI model, specifying "gpt-4". PydanticAI offers flexibility in model selection, allowing direct instantiation as shown, or via a more generic approach using <code>OpenAI(model_name="gpt-4")</code>. The more explicit method is favoured for clarity and reusability.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Next, we define a basic agent:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">basic_agent = Agent(
    model=model,
    system_prompt="Helpful customer support agent"
)
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">The <code>Agent</code> class acts as a container for essential elements: a system prompt, potential tools, desired result types, dependencies, and the chosen LLM model. At its core, an agent requires at least a model and a system prompt. In this basic example, the system prompt is straightforward: "Helpful customer support agent".</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Running this agent is simple:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">response = basic_agent.run_sync("How do I track my order?")
print(response.print_data())
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">The <code>run_sync</code> method executes the agent synchronously. PydanticAI also offers <code>run</code> for asynchronous execution and <code>run_stream</code> for streaming responses. The result is encapsulated in a <code>response</code> object, packed with information including the LLM's reply, message history, and cost metrics. Accessing <code>response.print_data()</code> reveals the model's answer, for instance: "To track your order, please check the confirmation email we sent to you."</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">The <code>response</code> object provides a wealth of detail. <code>response.messages</code> displays the full conversation history, including the system prompt, user prompt, and model reply. Even cost breakdowns are available via <code>response.cost</code>. For conversational applications, <code>response.messages</code> can be passed back into subsequent <code>agent.run_sync</code> calls, enabling seamless multi-turn dialogues.</p>

    <h3 style="color:#000;margin-top:25px;margin-bottom:10px;font-size:1.5em">Structured Output with Pydantic</h3>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Moving beyond simple text responses, PydanticAI truly shines when structuring LLM outputs using Pydantic models. Let's define a <code>ResponseModel</code>:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">from pydantic import BaseModel

class ResponseModel(BaseModel):
    response: str
    needs_escalation: bool
    followup_required: bool
    sentiment: str
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">This model dictates the desired structure of the LLM's reply. Now, we create an agent that leverages this model:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">structured_agent = Agent[ResponseModel]( # Note the type hint here
    model=model,
    result_type=ResponseModel,
    system_prompt="Helpful customer support agent that provides structured responses."
)

structured_response = structured_agent.run_sync("How do I track my order?")
print(structured_response.data.model_dump_json(indent=2))
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Crucially, note the type hint <code>Agent[ResponseModel]</code> and the <code>result_type=ResponseModel</code> parameter. This instructs PydanticAI to validate the LLM's output against the <code>ResponseModel</code> schema. The <code>structured_response.data</code> now contains a fully validated <code>ResponseModel</code> instance, not just raw text. <code>model_dump_json(indent=2)</code> neatly displays the structured JSON output, revealing fields like <code>response</code>, <code>needs_escalation</code>, <code>followup_required</code>, and <code>sentiment</code> populated by the LLM in accordance with the defined schema.</p>

    <h3 style="color:#000;margin-top:25px;margin-bottom:10px;font-size:1.5em">Dependency Injection for Contextual Awareness</h3>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">PydanticAI's dependency injection system elevates agent capabilities significantly. Imagine a customer service scenario where agent responses need to be tailored to specific customer details. Let's define Pydantic models for <code>Customer</code> and <code>Order</code> information:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">class Order(BaseModel):
    order_id: str
    items: list[str]

class CustomerDetails(BaseModel):
    customer_id: str
    name: str
    email: str
    orders: list[Order]
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Now, we define an agent that depends on <code>CustomerDetails</code>:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">dependency_agent = Agent[ResponseModel, CustomerDetails]( # Type hint with ResponseModel and CustomerDetails
    model=model,
    result_type=ResponseModel,
    dependency_type=CustomerDetails,
    system_prompt="Helpful customer support agent, contextual aware."
)
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Again, type hints are key: <code>Agent[ResponseModel, CustomerDetails]</code> and <code>dependency_type=CustomerDetails</code>. To inject dynamic customer information into the system prompt, we use a decorator:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">from pydantic_ai import RunContext

@dependency_agent.add_system_prompt
async def add_customer_name(context: RunContext[CustomerDetails]):
    customer_md = context.dependencies.to_markdown() # Assuming a to_markdown utility function exists
    return f"Customer Details:\n{customer_md}"
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">The <code>@dependency_agent.add_system_prompt</code> decorator registers the <code>add_customer_name</code> function to dynamically modify the system prompt. It leverages the <code>RunContext</code> to access injected dependencies. Here, it converts the <code>CustomerDetails</code> Pydantic model to Markdown for better LLM readability and injects it into the system prompt.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Let's instantiate a <code>CustomerDetails</code> object and run the agent:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">customer = CustomerDetails(
    customer_id="123",
    name="John Doe",
    email="john.doe@example.com",
    orders=[Order(order_id="456", items=["item1", "item2"])]
)

dependency_response = dependency_agent.run_sync(
    "What did I order?",
    dependency=customer # Injecting the dependency here
)
print(dependency_response.messages) # Inspecting the messages to see injected prompt
print(dependency_response.data) # Inspecting the structured response
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">When running <code>dependency_agent.run_sync</code>, we pass the <code>customer</code> object as the <code>dependency</code>. Inspecting <code>dependency_response.messages</code> reveals that the system prompt now <em>includes</em> the customer details, dynamically injected. The LLM, aware of the customer context, can provide a more informed and personalised response.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Furthermore, PydanticAI's dependency injection provides robust validation. If, for example, the <code>customer_id</code> in the incoming data is unexpectedly an integer instead of a string (as defined in the <code>CustomerDetails</code> model), PydanticAI will raise a validation error <em>before</em> the request even reaches the LLM. This early validation is crucial for building reliable production systems.</p>

    <h3 style="color:#000;margin-top:25px;margin-bottom:10px;font-size:1.5em">Tools: Extending Agent Capabilities</h3>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Agents are not limited to just system prompts and data; they can also utilise tools – functions that extend their capabilities. Consider a scenario where an agent needs to fetch shipping information. First, we define a simple "database" (in reality, this could be an API call or database query):</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">shipping_info_db = {
    "ORDER12345": {"status": "Shipped", "date": "1st of December"}
}

def get_shipping_info(context: RunContext[CustomerDetails]) -&gt; str:
    order_id = context.dependencies.orders[0].order_id
    info = shipping_info_db.get(f"ORDER{order_id}")
    if info:
        return f"Shipped on {info['date']}"
    return "Shipping information not found."
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">This <code>get_shipping_info</code> function (acting as our tool) retrieves shipping status based on the order ID from the injected <code>CustomerDetails</code> context. Now, we define an agent and register this tool:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">tool_agent = Agent[ResponseModel, CustomerDetails](
    model=model,
    result_type=ResponseModel,
    dependency_type=CustomerDetails,
    system_prompt="Helpful customer support agent that can access shipping information.",
    tools=[get_shipping_info] # Registering the tool here
)
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">We register <code>get_shipping_info</code> as a tool within the <code>tool_agent</code>. Note the two types of tools available: <code>Tool</code> and <code>ToolPlane</code>. <code>Tool</code> (used here implicitly as the function signature implies context dependency) is for tools that require agent context, while <code>ToolPlane</code> is for context-independent tools.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Running the agent with a user query about order status:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">tool_response = tool_agent.run_sync(
    "What is the status of my last order?",
    dependency=customer
)
print(tool_response.messages) # Inspect the messages - tool call should be visible
print(tool_response.data) # Inspect the final response
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Examining <code>tool_response.messages</code> reveals the agent's thought process: it identifies the need for shipping information, calls the <code>get_shipping_info</code> tool, receives the tool's output, and incorporates it into the final response. The response to the user becomes: "Hello John, your last order (ID: 456) was shipped on 1st of December."</p>

    <h3 style="color:#000;margin-top:25px;margin-bottom:10px;font-size:1.5em">Reflection and Self-Correction: Handling Errors Gracefully</h3>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">PydanticAI goes a step further, providing mechanisms for reflection and self-correction. Imagine a scenario where the shipping information database has an inconsistency – order IDs are prefixed with "#" but the incoming order data doesn't include it. This would lead to failed lookups. PydanticAI's <code>ModelRetry</code> mechanism can address such situations.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Let's modify the <code>get_shipping_info</code> tool to simulate this error and introduce a retry mechanism:</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">from pydantic_ai import ModelRetry, tool_decorator

shipping_info_db_corrected = {
    "#ORDER12345": {"status": "Shipped", "date": "1st of December"} # Order IDs with '#' prefix
}

@tool_decorator() # Explicitly using decorator for Tool registration
def get_shipping_info_retry(context: RunContext) -&gt; str: # ToolPlane example - no CustomerDetails context
    order_id_from_query = context.user_prompt.split()[-1] # Extract order ID from user query (simplistic example)
    info = shipping_info_db_corrected.get(f"#{order_id_from_query}") # Corrected lookup with '#'
    if info:
        return f"Shipped on {info['date']}"
    raise ModelRetry("No information found for this order. Make sure the order ID is correct, including any prefixes like '#'.") # Raise ModelRetry on lookup failure
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Here, we use the <code>@tool_decorator()</code> to explicitly register the tool and demonstrate a <code>ToolPlane</code> example, where the tool <em>doesn't</em> rely on the <code>CustomerDetails</code> dependency. Instead, it extracts the order ID directly from the user prompt (a simplified approach for demonstration). Crucially, if the database lookup fails, we raise a <code>ModelRetry</code> exception with a specific instruction for the LLM.</p>

    <pre style="background-color:#f4f4f4;padding:10px;border:1px solid #ddd;border-radius:5px;overflow-x:auto;margin-bottom:15px"><code style="color:#222;display:block;white-space:pre;font-size:.9em">retry_agent = Agent[ResponseModel, CustomerDetails](
    model=model,
    result_type=ResponseModel,
    dependency_type=CustomerDetails,
    system_prompt="Helpful customer support agent with retry mechanism.",
    tools=[get_shipping_info_retry], # Using the retry-enabled tool
    retries=3 # Agent-level retry limit
)

retry_response = retry_agent.run_sync(
    "What is the status of my last order 12345?", # Note order ID without '#'
    dependency=customer
)
print(retry_response.messages) # Observe retry prompts in messages
print(retry_response.data) # Final response after retry/correction
</code></pre>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">When <code>get_shipping_info_retry</code> raises <code>ModelRetry</code>, PydanticAI intercepts it. It injects the <code>ModelRetry</code> message back into the prompt, instructing the LLM to reflect and self-correct. In this example, the LLM, upon seeing the retry prompt, might infer that it needs to prepend "#" to the order ID before the database lookup. PydanticAI then re-executes the agent (up to the <code>retries=3</code> limit). In a successful retry, the corrected order ID (with "#") would lead to a successful database lookup, and the agent would then return the correct shipping information.</p>

    <h2 style="color:#000;margin-top:30px;margin-bottom:15px;font-size:1.8em">Initial Thoughts and Future Potential</h2>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">PydanticAI, even in its early stages, demonstrates a compelling approach to GenAI framework design. It successfully transplants the core Pydantic philosophy – rigorous data validation and structured data handling – into the agent development domain. The emphasis on clear abstractions and Pythonic idioms makes it remarkably approachable, especially for developers already familiar with the Pydantic ecosystem.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">The dependency injection system stands out as particularly elegant and powerful, offering a clean way to manage context and enhance agent adaptability. The tool mechanism further extends agent capabilities, allowing seamless integration with external data sources and services. And the inclusion of <code>ModelRetry</code> for reflection and self-correction hints at a framework designed for robustness and real-world deployment.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">However, it's important to acknowledge that PydanticAI is currently in beta. As with any young framework, changes are expected. During initial explorations, some limitations were encountered, such as the apparent lack of direct control over model parameters like temperature, and occasional issues with message history and tool interactions. These are likely areas of active development and refinement.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">Despite these early-stage considerations, PydanticAI shows immense promise. Its lean, low-level approach provides developers with a clear understanding of the underlying mechanics, contrasting with more opaque, "batteries-included" frameworks. PydanticAI feels more like a toolkit of well-defined components than a monolithic solution, offering greater flexibility and control.</p>

    <h2 style="color:#000;margin-top:30px;margin-bottom:15px;font-size:1.8em">Conclusion: A Promising Tool in the GenAI Landscape</h2>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">PydanticAI is not aiming to be an all-encompassing GenAI solution. Instead, it carves a niche as a powerful <em>tool</em> for structuring and validating interactions with LLMs. It empowers developers to build robust, type-safe, and maintainable AI applications by bringing order and clarity to the often-complex world of agent development.</p>

    <p style="color:#000;margin-bottom:15px;font-size:1.1em">While still in its early stages, PydanticAI's foundation, built upon the proven principles of Pydantic, suggests a bright future. For developers seeking a framework that prioritises structure, validation, and Pythonic elegance in their GenAI projects, PydanticAI is definitely one to watch – and to experiment with. Rather than immediately migrating entire production systems, a prudent approach would be to explore PydanticAI, extract valuable concepts like dependency injection and structured outputs, and selectively integrate them into existing workflows. The framework's focus on being a composable tool, rather than a monolithic solution, makes this kind of selective adoption particularly appealing.</p>
</div><p>
```</p></div></section><section class="mb-3"><h4 class="section-title explore-more"><span>Explore More</span></h4><div class=""><div class="card mb-3 d-flex flex-row has-img"><div class="col-2 p-0 explore-featured-image"><a class="card-img-left card-has-img" href="https://ccwithai.github.io/AI/blog/lovable-and-bolt-new/"><img src="https://ccwithai.github.io/AI/assets/images/a5741e405d.png" loading="lazy"></a></div><div class="card-body col"><a class="card-title" href="https://ccwithai.github.io/AI/blog/lovable-and-bolt-new/">I Built a SaaS starter website for Free with Lovable</a><p class="card-text">I Built a SaaS starter website for Free with Lovab...</p></div></div></div></section></div></div></div></div></main><footer class="page-footer"><div class="container"><div class="row"><div class="col col-12 col-md-6"><span>© <!-- -->AI</span></div><div class="col col-12 col-md-6 mt-3 mt-md-0 d-flex justify-content-md-end"><a href="https://prss.io" class="d-flex align-items-center footer-shoutout" target="_blank" rel="noopener" title="Powered by PRSS Site Creator"><img class="prss-footer-image mr-1" src="data:image/png;base64,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" width="15"><span class="font-weight-bold prss-tag">PRSS Site Creator</span></a></div></div></div></footer></div></div>

</body></html>